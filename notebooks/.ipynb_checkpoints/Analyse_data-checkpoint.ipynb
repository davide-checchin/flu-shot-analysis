{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147189f4-f887-445e-b94f-e7325e374436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/p8vjfvvx3qx7blvj4038zc480000gp/T/ipykernel_80746/2130804501.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b146eda1-3f2f-428a-90dc-e83ef1a0c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../data/training_set_features.csv\")\n",
    "y_train = pd.read_csv(\"../data/training_set_labels.csv\")\n",
    "X_test = pd.read_csv(\"../data/test_set_features.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bfd519-652e-48e0-af6d-c3e2fad7de90",
   "metadata": {},
   "source": [
    "## First looks to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd10be7c-dd9a-4d5e-926c-1a919643bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26707, 36)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6fafdc-0599-46c2-9b41-9f3e7d28bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
      "0              0           1.0             0.0                        0.0   \n",
      "1              1           3.0             2.0                        0.0   \n",
      "2              2           1.0             1.0                        0.0   \n",
      "\n",
      "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
      "0                   0.0                   0.0                    0.0   \n",
      "1                   1.0                   0.0                    1.0   \n",
      "2                   1.0                   0.0                    0.0   \n",
      "\n",
      "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
      "0                          0.0                      1.0   \n",
      "1                          0.0                      1.0   \n",
      "2                          0.0                      0.0   \n",
      "\n",
      "   behavioral_touch_face  ...             income_poverty  marital_status  \\\n",
      "0                    1.0  ...              Below Poverty     Not Married   \n",
      "1                    1.0  ...              Below Poverty     Not Married   \n",
      "2                    0.0  ...  <= $75,000, Above Poverty     Not Married   \n",
      "\n",
      "   rent_or_own   employment_status  hhs_geo_region                census_msa  \\\n",
      "0          Own  Not in Labor Force        oxchjgsf                   Non-MSA   \n",
      "1         Rent            Employed        bhuqouqj  MSA, Not Principle  City   \n",
      "2          Own            Employed        qufhixun  MSA, Not Principle  City   \n",
      "\n",
      "   household_adults  household_children  employment_industry  \\\n",
      "0               0.0                 0.0                  NaN   \n",
      "1               0.0                 0.0             pxcmvdjn   \n",
      "2               2.0                 0.0             rucpziij   \n",
      "\n",
      "   employment_occupation  \n",
      "0                    NaN  \n",
      "1               xgwztkwe  \n",
      "2               xtkaffoo  \n",
      "\n",
      "[3 rows x 36 columns]\n",
      "       respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
      "count   26707.000000  26615.000000    26591.000000               26636.000000   \n",
      "mean    13353.000000      1.618486        1.262532                   0.048844   \n",
      "std      7709.791156      0.910311        0.618149                   0.215545   \n",
      "min         0.000000      0.000000        0.000000                   0.000000   \n",
      "25%      6676.500000      1.000000        1.000000                   0.000000   \n",
      "50%     13353.000000      2.000000        1.000000                   0.000000   \n",
      "75%     20029.500000      2.000000        2.000000                   0.000000   \n",
      "max     26706.000000      3.000000        2.000000                   1.000000   \n",
      "\n",
      "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
      "count          26499.000000          26688.000000           26665.000000   \n",
      "mean               0.725612              0.068982               0.825614   \n",
      "std                0.446214              0.253429               0.379448   \n",
      "min                0.000000              0.000000               0.000000   \n",
      "25%                0.000000              0.000000               1.000000   \n",
      "50%                1.000000              0.000000               1.000000   \n",
      "75%                1.000000              0.000000               1.000000   \n",
      "max                1.000000              1.000000               1.000000   \n",
      "\n",
      "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
      "count                  26620.00000             26625.000000   \n",
      "mean                       0.35864                 0.337315   \n",
      "std                        0.47961                 0.472802   \n",
      "min                        0.00000                 0.000000   \n",
      "25%                        0.00000                 0.000000   \n",
      "50%                        0.00000                 0.000000   \n",
      "75%                        1.00000                 1.000000   \n",
      "max                        1.00000                 1.000000   \n",
      "\n",
      "       behavioral_touch_face  ...  health_worker  health_insurance  \\\n",
      "count           26579.000000  ...   25903.000000       14433.00000   \n",
      "mean                0.677264  ...       0.111918           0.87972   \n",
      "std                 0.467531  ...       0.315271           0.32530   \n",
      "min                 0.000000  ...       0.000000           0.00000   \n",
      "25%                 0.000000  ...       0.000000           1.00000   \n",
      "50%                 1.000000  ...       0.000000           1.00000   \n",
      "75%                 1.000000  ...       0.000000           1.00000   \n",
      "max                 1.000000  ...       1.000000           1.00000   \n",
      "\n",
      "       opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
      "count                 26316.000000       26319.000000   \n",
      "mean                      3.850623           2.342566   \n",
      "std                       1.007436           1.285539   \n",
      "min                       1.000000           1.000000   \n",
      "25%                       3.000000           1.000000   \n",
      "50%                       4.000000           2.000000   \n",
      "75%                       5.000000           4.000000   \n",
      "max                       5.000000           5.000000   \n",
      "\n",
      "       opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
      "count                 26312.000000                 26245.000000   \n",
      "mean                      2.357670                     4.025986   \n",
      "std                       1.362766                     1.086565   \n",
      "min                       1.000000                     1.000000   \n",
      "25%                       1.000000                     4.000000   \n",
      "50%                       2.000000                     4.000000   \n",
      "75%                       4.000000                     5.000000   \n",
      "max                       5.000000                     5.000000   \n",
      "\n",
      "       opinion_seas_risk  opinion_seas_sick_from_vacc  household_adults  \\\n",
      "count       26193.000000                 26170.000000      26458.000000   \n",
      "mean            2.719162                     2.118112          0.886499   \n",
      "std             1.385055                     1.332950          0.753422   \n",
      "min             1.000000                     1.000000          0.000000   \n",
      "25%             2.000000                     1.000000          0.000000   \n",
      "50%             2.000000                     2.000000          1.000000   \n",
      "75%             4.000000                     4.000000          1.000000   \n",
      "max             5.000000                     5.000000          3.000000   \n",
      "\n",
      "       household_children  \n",
      "count        26458.000000  \n",
      "mean             0.534583  \n",
      "std              0.928173  \n",
      "min              0.000000  \n",
      "25%              0.000000  \n",
      "50%              0.000000  \n",
      "75%              1.000000  \n",
      "max              3.000000  \n",
      "\n",
      "[8 rows x 24 columns]\n",
      "   respondent_id  h1n1_vaccine  seasonal_vaccine\n",
      "0              0             0                 0\n",
      "1              1             0                 1\n",
      "2              2             0                 0\n",
      "       respondent_id  h1n1_vaccine  seasonal_vaccine\n",
      "count   26707.000000  26707.000000      26707.000000\n",
      "mean    13353.000000      0.212454          0.465608\n",
      "std      7709.791156      0.409052          0.498825\n",
      "min         0.000000      0.000000          0.000000\n",
      "25%      6676.500000      0.000000          0.000000\n",
      "50%     13353.000000      0.000000          0.000000\n",
      "75%     20029.500000      0.000000          1.000000\n",
      "max     26706.000000      1.000000          1.000000\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head(3))\n",
    "print(X_train.describe())\n",
    "print(y_train.head(3))\n",
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12439c68-baf7-44be-a8ee-9078cb6ac790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage h1n1_vaccine:   21.24536638334519\n",
      "percentage seasonal_vaccine:   46.56082674954132\n"
     ]
    }
   ],
   "source": [
    "# percentage of h1n1_vaccine and of seasonal_vaccine -> could have been seen also by the mean\n",
    "\n",
    "print( f\"percentage h1n1_vaccine:   {y_train['h1n1_vaccine'].sum()/len(y_train)*100}\")\n",
    "print( f\"percentage seasonal_vaccine:   {y_train['seasonal_vaccine'].sum()/len(y_train)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30429fd4-807c-46a0-8677-2614f11219d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "respondent_id                      0\n",
       "h1n1_concern                      92\n",
       "h1n1_knowledge                   116\n",
       "behavioral_antiviral_meds         71\n",
       "behavioral_avoidance             208\n",
       "behavioral_face_mask              19\n",
       "behavioral_wash_hands             42\n",
       "behavioral_large_gatherings       87\n",
       "behavioral_outside_home           82\n",
       "behavioral_touch_face            128\n",
       "doctor_recc_h1n1                2160\n",
       "doctor_recc_seasonal            2160\n",
       "chronic_med_condition            971\n",
       "child_under_6_months             820\n",
       "health_worker                    804\n",
       "health_insurance               12274\n",
       "opinion_h1n1_vacc_effective      391\n",
       "opinion_h1n1_risk                388\n",
       "opinion_h1n1_sick_from_vacc      395\n",
       "opinion_seas_vacc_effective      462\n",
       "opinion_seas_risk                514\n",
       "opinion_seas_sick_from_vacc      537\n",
       "age_group                          0\n",
       "education                       1407\n",
       "race                               0\n",
       "sex                                0\n",
       "income_poverty                  4423\n",
       "marital_status                  1408\n",
       "rent_or_own                     2042\n",
       "employment_status               1463\n",
       "hhs_geo_region                     0\n",
       "census_msa                         0\n",
       "household_adults                 249\n",
       "household_children               249\n",
       "employment_industry            13330\n",
       "employment_occupation          13470\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look to the distribution of missing values \n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42a8f7-74a3-4f91-b87c-6799542bfaa9",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cf1daf-a9c7-40ac-8f96-e45ddebcc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to apply the preprocessing to both X_training and X_test, I create then a sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979155b1-914e-46f4-bfd4-61f19e45d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems that nans in some categories as emlpoyment industry and employment occuapations may be seen as a category itself (\"unemployed\")\n",
    "# I would rather not delete those observations that contains nans and I ll try to input instead a sensible values - (is risky but normally people doesnt want to share bad information)\n",
    "#There are not too many columns so i will apply the change column by column, i would keep some of them as nan and try to input the values later\n",
    "def fill_missing_values_with_adhoc_values(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"employment_occupation\"] = df[\"employment_occupation\"].fillna(\"unemployed\")\n",
    "    df[\"employment_industry\"] = df[\"employment_industry\"].fillna(\"unemployed\")\n",
    "    df[\"education\"] = df[\"education\"].fillna(\"< 12 Years\")\n",
    "    df[\"health_insurance\"] = df[\"health_insurance\"].fillna(0)\n",
    "    df[\"income_poverty\"] = df[\"income_poverty\"].fillna(\"Below Poverty\")\n",
    "    df[\"employment_status\"] = df[\"employment_status\"].fillna(\"Unemployed\")\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed077a76-0dc4-4f1d-ae34-30bf69fb62b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I m gonna fill the other missing values on the one hot encoded nana columns with KNNImputer, but first I need to convert the columns to one hot encoded \n",
    "# if they dont have an order or scale them to integer \n",
    "\n",
    "def convert_columns_to_one_hot_encoded(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    categorical_columns = [\"race\", \"sex\",\"marital_status\",\"rent_or_own\",\"employment_status\",\"hhs_geo_region\",\"census_msa\", \"employment_industry\", \"employment_occupation\"]\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop=\"if_binary\")\n",
    "    one_hot_encoded = encoder.fit_transform(df[categorical_columns])\n",
    "    df = pd.concat([df, pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))], axis=1)\n",
    "    df = df.drop(categorical_columns, axis=1)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6be8d6-2d82-4641-90c6-c77b6270c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets convert the categorical variables ordered variables to numeric variables \n",
    "\n",
    "def map_categorical_ordered_variables(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    category_mapping = {'Below Poverty': 1, '<= $75,000, Above Poverty': 2, '> $75,000': 3}\n",
    "    df['income_poverty'] = df['income_poverty'].map(category_mapping)\n",
    "    \n",
    "    category_mapping = {'< 12 Years': 1, '12 Years': 2, 'Some College': 3, 'College Graduate': 4}\n",
    "    df['education'] = df['education'].map(category_mapping)\n",
    "    \n",
    "    category_mapping = {'18 - 34 Years': 1, '35 - 44 Years': 2, '45 - 54 Years': 3, '55 - 64 Years' : 4, '65+ Years' : 5 }\n",
    "    df['age_group'] = df['age_group'].map(category_mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f731efc-729f-4172-9f0e-92ed46714614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets imput missing values, i could use both the dataframe togheter for that but they should be big enough to make it robust\n",
    "def imputing_missing_values(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    knn_imputer = KNNImputer(n_neighbors=10)\n",
    "    imputed_data = knn_imputer.fit_transform(df)\n",
    "    return imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291e4909-c506-4682-b9c1-69559237e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_useless_columns(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.drop(columns=[\"respondent_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "749fcf83-5e86-4ea7-9029-17615d903cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline(\n",
    "    steps=[(\"fill_known_missing_values\", FunctionTransformer(fill_missing_values_with_adhoc_values)),\n",
    "           (\"convert_columns_to_one_hot_encoded\", FunctionTransformer(convert_columns_to_one_hot_encoded)),\n",
    "           (\"map_categorical_ordered_variables\", FunctionTransformer(map_categorical_ordered_variables)),\n",
    "           (\"drop_useless_columns\", FunctionTransformer(drop_useless_columns)),\n",
    "           (\"impute_missing_values\", FunctionTransformer(imputing_missing_values)),    \n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26091f6d-445e-4c47-a554-8d42ae3267ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_test = preprocessing_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75fc65c9-ffd3-4617-a18c-5e4fb1a3568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test is just for the submission, to avoid overfitting I split the training set to train and validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ffb93a-0bfd-474a-8db4-78926488055f",
   "metadata": {},
   "source": [
    "## Start training and get the first predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d6f022b-c17a-4964-8b36-720f0778d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19a0867a-389d-412d-8001-7410ce1c9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction with a logistic regression with imbalanced classes to have a baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f57a3d5-911c-4739-8a2a-186a91d94ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davide.checchin/.asdf/installs/python/3.10.12/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/davide.checchin/.asdf/installs/python/3.10.12/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "logreg_model_h1n1 = LogisticRegression(max_iter = 1000)\n",
    "logreg_model_h1n1.fit(X_train, y_train[[\"h1n1_vaccine\"]])\n",
    "y_pred_h1h1 = logreg_model_h1n1.predict(X_validation)\n",
    "y_pred_h1h1_probs = logreg_model_h1n1.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "\n",
    "logreg_model_seasonal = LogisticRegression(max_iter = 1000)\n",
    "logreg_model_seasonal.fit(X_train, y_train[[\"seasonal_vaccine\"]])\n",
    "y_pred_seasonal = logreg_model_seasonal.predict(X_validation)\n",
    "y_pred_seasonal_probs = logreg_model_seasonal.predict_proba(X_validation)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "845c84c9-da7b-424f-a085-d69e6fbcda7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline h1n1 score:   0.7190492398457\n",
      "baseline seasonal score:      0.7821854173696531\n",
      "baseline h1n1 score with probabilities:   0.8603786904671862\n",
      "baseline seasonal score with probabilities:      0.8565199247344104\n"
     ]
    }
   ],
   "source": [
    "h1n1_score = roc_auc_score(y_validation[\"h1n1_vaccine\"] ,y_pred_h1h1)\n",
    "seasonal_score = roc_auc_score(y_validation[\"seasonal_vaccine\"] ,y_pred_seasonal)\n",
    "print(f\"baseline h1n1 score:   {h1n1_score}\")\n",
    "print(f\"baseline seasonal score:      {seasonal_score}\")\n",
    "\n",
    "h1n1_score_probs = roc_auc_score(y_validation[\"h1n1_vaccine\"] ,y_pred_h1h1_probs)\n",
    "seasonal_score_probs = roc_auc_score(y_validation[\"seasonal_vaccine\"] ,y_pred_seasonal_probs)\n",
    "print(f\"baseline h1n1 score with probabilities:   {h1n1_score_probs}\")\n",
    "print(f\"baseline seasonal score with probabilities:      {seasonal_score_probs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "877c0f78-6f5a-4f47-bd0b-0834df5a7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try again with undersample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acd6cee6-b4e3-47bf-a54a-4a4659e9a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled_h1n1, y_resampled_h1n1 = under_sampler.fit_resample(X_train, y_train[\"h1n1_vaccine\"])\n",
    "X_resampled_seasonal, y_resampled_seasonal = under_sampler.fit_resample(X_train, y_train[\"seasonal_vaccine\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5990fe79-c35b-4fd9-9c95-221cba133283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using probabilities it s not stricktly necessary to resample datas \n",
    "\n",
    "logreg_model_h1n1 = LogisticRegression(max_iter = 1000)\n",
    "logreg_model_h1n1.fit(X_resampled_h1n1, y_resampled_h1n1)\n",
    "y_pred_h1h1 = logreg_model_h1n1.predict(X_validation)\n",
    "y_pred_h1h1_probs = logreg_model_h1n1.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "logreg_model_seasonal = LogisticRegression(max_iter = 1000)\n",
    "logreg_model_seasonal.fit(X_resampled_seasonal, y_resampled_seasonal)\n",
    "y_pred_seasonal = logreg_model_seasonal.predict(X_validation)\n",
    "y_pred_seasonal_probs = logreg_model_seasonal.predict_proba(X_validation)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26c5b4fc-9139-4297-b7ec-089a054fdbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline h1n1 score:   0.78393485952483\n",
      "baseline seasonal score:      0.7871126377235955\n"
     ]
    }
   ],
   "source": [
    "h1n1_score = roc_auc_score(y_validation[\"h1n1_vaccine\"] ,y_pred_h1h1)\n",
    "seasonal_score = roc_auc_score(y_validation[\"seasonal_vaccine\"] ,y_pred_seasonal)\n",
    "print(f\"baseline h1n1 score:   {h1n1_score}\")\n",
    "print(f\"baseline seasonal score:      {seasonal_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b657cc8-c79d-4a95-8266-7d827ba6e6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline h1n1 score with probabilities:   0.8597204363428551\n",
      "baseline seasonal score with probabilities:      0.8563501495447046\n"
     ]
    }
   ],
   "source": [
    "h1n1_score = roc_auc_score(y_validation[\"h1n1_vaccine\"] ,y_pred_h1h1_probs)\n",
    "seasonal_score = roc_auc_score(y_validation[\"seasonal_vaccine\"] ,y_pred_seasonal_probs)\n",
    "print(f\"baseline h1n1 score with probabilities:   {h1n1_score}\")\n",
    "print(f\"baseline seasonal score with probabilities:      {seasonal_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14a288-ee8a-4464-abda-83471f013cde",
   "metadata": {},
   "source": [
    "## Proceed with more advanced models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b941a5-6c8d-4898-a431-967826f6a79b",
   "metadata": {},
   "source": [
    "### Xgboost with default params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "991ed54c-e9b3-41e9-9ea5-0a7788e59e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11a2d962-29eb-4a69-b1b2-5287591f6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc') # I use AUC as metrix because is the competition metric\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train[[\"h1n1_vaccine\"]])\n",
    "xgb_y_pred_h1n1 = xgb_classifier.predict(X_validation)\n",
    "xgb_y_pred_h1n1_probs = xgb_classifier.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train[[\"seasonal_vaccine\"]])\n",
    "xgb_y_pred_seasonal = xgb_classifier.predict(X_validation)\n",
    "xgb_y_pred_seasonal_probs = xgb_classifier.predict_proba(X_validation)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e390ad32-10f0-4aa2-85ed-213e0cc28cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline h1n1 score:   0.7320540133961964\n",
      "baseline seasonal score:      0.7829836994648907\n",
      "baseline h1n1 score with probabilities:   0.8590554589079663\n",
      "baseline seasonal score with probabilities:      0.8583283903773737\n"
     ]
    }
   ],
   "source": [
    "xgb_h1n1_score = roc_auc_score(y_validation[\"h1n1_vaccine\"] ,xgb_y_pred_h1n1)\n",
    "xgb_seasonal_score = roc_auc_score(y_validation[\"seasonal_vaccine\"] ,xgb_y_pred_seasonal)\n",
    "print(f\"baseline h1n1 score:   {xgb_h1n1_score}\")\n",
    "print(f\"baseline seasonal score:      {xgb_seasonal_score}\")\n",
    "\n",
    "xgb_h1n1_score_probs = roc_auc_score(y_validation[\"h1n1_vaccine\"] ,xgb_y_pred_h1n1_probs)\n",
    "xgb_seasonal_score_probs = roc_auc_score(y_validation[\"seasonal_vaccine\"] ,xgb_y_pred_seasonal_probs)\n",
    "print(f\"baseline h1n1 score with probabilities:   {xgb_h1n1_score_probs}\")\n",
    "print(f\"baseline seasonal score with probabilities:      {xgb_seasonal_score_probs}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a78fdd4-b734-4426-9412-7f97cbec5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results are slightly better than the baseline, let s optimize the HP for the xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65293153-8776-4805-9150-0a3832f72bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters h1n1: OrderedDict([('colsample_bytree', 0.8925589692663731), ('learning_rate', 0.05822186589792438), ('max_depth', 5), ('n_estimators', 137), ('subsample', 0.8)])\n",
      "Best Hyperparameters seasonal: OrderedDict([('colsample_bytree', 0.8), ('learning_rate', 0.08440619119260946), ('max_depth', 4), ('n_estimators', 150), ('subsample', 0.8)])\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc')\n",
    "\n",
    "param_space = {\n",
    "    'learning_rate': (0.01, 0.2, 'log-uniform'),\n",
    "    'n_estimators': (50, 150),\n",
    "    'max_depth': (3, 7),\n",
    "    'subsample': (0.8, 1.0),\n",
    "    'colsample_bytree': (0.8, 1.0),\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb_classifier,\n",
    "    search_spaces=param_space,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_iter=50,  # Number of iterations (adjust as needed)\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "np.int = int # to solve some error with numpy version in the skopt library\n",
    "\n",
    "# Fit the Bayesian search to the data\n",
    "bayes_search.fit(X_train, y_train[[\"h1n1_vaccine\"]])\n",
    "best_params_h1n1 = bayes_search.best_params_\n",
    "print(\"Best Hyperparameters h1n1:\", best_params_h1n1)\n",
    "\n",
    "bayes_search.fit(X_train, y_train[[\"seasonal_vaccine\"]])\n",
    "best_params_seasonal = bayes_search.best_params_\n",
    "print(\"Best Hyperparameters seasonal:\", best_params_seasonal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9f8b411-7b08-41fd-89a5-9cb09c2452ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use those params to train and see if the predictions are more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de33b19c-aca0-4b5f-9b6e-fcaa04c31a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline h1n1 score with probabilities:   0.8733506878787116\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                   eval_metric='auc',\n",
    "                                   colsample_bytree = 0.8,\n",
    "                                   learning_rate = 0.0654,\n",
    "                                   max_depth = 4,\n",
    "                                   n_estimators = 150,\n",
    "                                   subsample = 0.8                               \n",
    "                                  ) # I use AUC as metrix because is the competition metric\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train[[\"h1n1_vaccine\"]])\n",
    "xgb_y_pred_h1n1_probs = xgb_classifier.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "xgb_h1n1_score_probs = roc_auc_score(y_validation[\"h1n1_vaccine\"] ,xgb_y_pred_h1n1_probs)\n",
    "print(f\"baseline h1n1 score with probabilities:   {xgb_h1n1_score_probs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2af5284b-649d-4941-9d03-a7718dea44bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline seasonal score with probabilities:      0.8675132563657582\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                   eval_metric='auc',\n",
    "                                   colsample_bytree = 0.8,\n",
    "                                   learning_rate = 0.0559,\n",
    "                                   max_depth = 5,\n",
    "                                   n_estimators = 150,\n",
    "                                   subsample = 0.8                               \n",
    "                                  ) # I use AUC as metrix because is the competition metric\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train[[\"seasonal_vaccine\"]])\n",
    "xgb_y_pred_seasonal_probs = xgb_classifier.predict_proba(X_validation)[:, 1]\n",
    "xgb_seasonal_score_probs = roc_auc_score(y_validation[\"seasonal_vaccine\"] ,xgb_y_pred_seasonal_probs)\n",
    "print(f\"baseline seasonal score with probabilities:      {xgb_seasonal_score_probs}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9007b-e2f4-4cf2-8c1f-6ccad9611987",
   "metadata": {},
   "source": [
    "#### The results looks promising and if confirmed on the test set they would bring me to the first place of the partial leaderboard among more than 6000 candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818696e-8a56-4ef7-a225-a22b8c563d6f",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f14c6140-aac2-46c0-a8b7-57969f353128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcd1f9-87d3-47d9-89e8-d681c6b4db5d",
   "metadata": {},
   "source": [
    "#### Instead of Bayesian optimization this time we run 5 fold CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2358781-25c0-4304-8eae-a49ed62eb98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(3, 20)),  \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # try different distances: 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "scorer = make_scorer(roc_auc_score)\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring=scorer)\n",
    "grid_search.fit(X_train, y_train[\"h1n1_vaccine\"])\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters h1n1_vaccine:\", best_params)\n",
    "\n",
    "grid_search.fit(X_train, y_train[\"seasonal_vaccine\"])\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters seasonal_vaccine:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9147a4b-9656-4066-a563-ad59d0d4257e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7769285396129053"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7, p = 1, weights = \"distance\")\n",
    "knn.fit(X_train, y_train[\"h1n1_vaccine\"])\n",
    "knn_h1n1_predictions = knn.predict_proba(X_validation)[:, 1]\n",
    "roc_auc_score(y_validation[\"h1n1_vaccine\"], knn_h1n1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c3c4157-328e-4f49-b328-a2b9ad96378d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833150856757864"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=19, p = 1, weights = \"uniform\")\n",
    "knn.fit(X_train, y_train[\"seasonal_vaccine\"])\n",
    "knn_seasonal_predictions = knn.predict_proba(X_validation)[:, 1]\n",
    "roc_auc_score(y_validation[\"seasonal_vaccine\"], knn_seasonal_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ac29a-565c-4eb4-b496-df49b63802e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
